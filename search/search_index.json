{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AllenNLP-Hydra # Documentation Plugin For AllenNLP that enables composing configs through the use of the Hydra Library from Facebook Research . NOTE there is no affiliation between this project and AllenNLP or the Allen Institute for AI. We use the same contributions guideline as AllenNLP in order to maintain similar code styles. For this reason our style guide is the same as that found in their repository . Install Instructions # pip install allennlp-hydra echo allennlp_hydra >> ~.allennlp_plugins The second line adds allennlp-hydra to the allennlp plugins file so that it can globally be recognized. Basic Guide # Say you have the following directory structure: project +-- conf | +-- dataset_readers | | +-- A.yaml | | +-- B.yaml | +-- models | | +-- C.yaml | | +-- D.yaml | +-- config.yaml +-- experiments conf/dataset_readers/A.yaml : type: A start_token: <s> end_token: </s> conf/dataset_readers/B.yaml : type: B start_token: [CLS] end_token: [SEP] conf/models/C.yaml : type: C layers: 5 conf/models/D.yaml : type : D input_dim : 10 config.yaml defaults: - dataset_reader: A - model: C debug: false Then running the command allennlp compose conf config example -s experiments Produces the file project/experiments/config.json { \"dataset_reader\" :{ \"type\" : \"A\" , \"start_token\" : \"<s>\" , \"end_token\" : \"</s>\" }, \"model\" : { \"type\" : \"C\" , \"layers\" : 5 }, \"debug\" : false } If you want to override the config and use the B dataset reader with the D model, you would modify the previous command: allennlp compose conf config example -s experiments -o model = D dataset_reader = B Produces the file project/experiments/config.json { \"dataset_reader\" :{ \"type\" : \"B\" , \"start_token\" : \"[CLS]\" , \"end_token\" : \"[SEP]\" }, \"model\" : { \"type\" : \"D\" , \"input_dim\" : 10 }, \"debug\" : false } And if you wanted to change input_dim of model D to 25: allennlp compose conf config example -s experiments -o model = D dataset_reader = B model.input_dim = 25 Produces the file project/experiments/config.json { \"dataset_reader\" :{ \"type\" : \"B\" , \"start_token\" : \"[CLS]\" , \"end_token\" : \"[SEP]\" }, \"model\" : { \"type\" : \"D\" , \"input_dim\" : 25 }, \"debug\" : false }","title":"Home"},{"location":"#allennlp-hydra","text":"Documentation Plugin For AllenNLP that enables composing configs through the use of the Hydra Library from Facebook Research . NOTE there is no affiliation between this project and AllenNLP or the Allen Institute for AI. We use the same contributions guideline as AllenNLP in order to maintain similar code styles. For this reason our style guide is the same as that found in their repository .","title":"AllenNLP-Hydra"},{"location":"#install-instructions","text":"pip install allennlp-hydra echo allennlp_hydra >> ~.allennlp_plugins The second line adds allennlp-hydra to the allennlp plugins file so that it can globally be recognized.","title":"Install Instructions"},{"location":"#basic-guide","text":"Say you have the following directory structure: project +-- conf | +-- dataset_readers | | +-- A.yaml | | +-- B.yaml | +-- models | | +-- C.yaml | | +-- D.yaml | +-- config.yaml +-- experiments conf/dataset_readers/A.yaml : type: A start_token: <s> end_token: </s> conf/dataset_readers/B.yaml : type: B start_token: [CLS] end_token: [SEP] conf/models/C.yaml : type: C layers: 5 conf/models/D.yaml : type : D input_dim : 10 config.yaml defaults: - dataset_reader: A - model: C debug: false Then running the command allennlp compose conf config example -s experiments Produces the file project/experiments/config.json { \"dataset_reader\" :{ \"type\" : \"A\" , \"start_token\" : \"<s>\" , \"end_token\" : \"</s>\" }, \"model\" : { \"type\" : \"C\" , \"layers\" : 5 }, \"debug\" : false } If you want to override the config and use the B dataset reader with the D model, you would modify the previous command: allennlp compose conf config example -s experiments -o model = D dataset_reader = B Produces the file project/experiments/config.json { \"dataset_reader\" :{ \"type\" : \"B\" , \"start_token\" : \"[CLS]\" , \"end_token\" : \"[SEP]\" }, \"model\" : { \"type\" : \"D\" , \"input_dim\" : 10 }, \"debug\" : false } And if you wanted to change input_dim of model D to 25: allennlp compose conf config example -s experiments -o model = D dataset_reader = B model.input_dim = 25 Produces the file project/experiments/config.json { \"dataset_reader\" :{ \"type\" : \"B\" , \"start_token\" : \"[CLS]\" , \"end_token\" : \"[SEP]\" }, \"model\" : { \"type\" : \"D\" , \"input_dim\" : 25 }, \"debug\" : false }","title":"Basic Guide"},{"location":"CHANGELOG/","text":"Changelog # All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . Unreleased #","title":"CHANGELOG"},{"location":"CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"CHANGELOG/#unreleased","text":"","title":"Unreleased"},{"location":"hydra/commands/class_to_yaml/","text":"allennlp_hydra .commands .class_to_yaml [SOURCE] Command to convert a class to a yaml. Registered as cls2yml ClassToYaml # @Subcommand . register ( \"class2yaml\" ) class ClassToYaml ( Subcommand ) add_subparser # class ClassToYaml ( Subcommand ): | ... | @overrides | def add_subparser ( | self , | parser : argparse . _SubParsersAction | ) -> argparse . ArgumentParser class_to_yaml_from_args # def class_to_yaml_from_args ( args : argparse . Namespace ) -> Dict class_to_yaml # def class_to_yaml ( cls_name : str , base_cls_name : str , serialization_dir : str , force : bool = False ) -> Dict","title":"class_to_yaml"},{"location":"hydra/commands/class_to_yaml/#classtoyaml","text":"@Subcommand . register ( \"class2yaml\" ) class ClassToYaml ( Subcommand )","title":"ClassToYaml"},{"location":"hydra/commands/class_to_yaml/#add_subparser","text":"class ClassToYaml ( Subcommand ): | ... | @overrides | def add_subparser ( | self , | parser : argparse . _SubParsersAction | ) -> argparse . ArgumentParser","title":"add_subparser"},{"location":"hydra/commands/class_to_yaml/#class_to_yaml_from_args","text":"def class_to_yaml_from_args ( args : argparse . Namespace ) -> Dict","title":"class_to_yaml_from_args"},{"location":"hydra/commands/class_to_yaml/#class_to_yaml","text":"def class_to_yaml ( cls_name : str , base_cls_name : str , serialization_dir : str , force : bool = False ) -> Dict","title":"class_to_yaml"},{"location":"hydra/commands/compose_config/","text":"allennlp_hydra .commands .compose_config [SOURCE] The compose command creates an AllenNLP config by composing a set of yaml files with Hydra's Compose API . Overriding using Hydra's Override Grammar is also supported. Parameters \u00b6 config_path : Union[str, PathLike] Path to the root config directory. config_name : str The name of the root config file. Do NOT include the .yaml . job_name : str The job name. This is passed to Hydra and is not used here. -s/--serialization-dir : Union[str, PathLike] The directory where the new AllenNLP config will be saved to. The name used for saving will be the config_name and it will be a .json file. -o/--overrides : List[str] , optional (default = [] ) Keyword arguments passed will be used as a list of overrides using Hydra's override grammar for the config. Example usage: allennlp compose conf config example -s example --overrides A = B C = \"D\" Will be interpreted as overrides ['A=B', 'C=\"D\"'] Example \u00b6 Say you have the following directory structure: project +-- conf | +-- dataset_readers | | +-- A.yaml | | +-- B.yaml | +-- models | | +-- C.yaml | | +-- D.yaml | +-- config.yaml +-- experiments conf/dataset_readers/A.yaml : type: A start_token: <s> end_token: </s> conf/dataset_readers/B.yaml : type: B start_token: [CLS] end_token: [SEP] conf/models/C.yaml : type: C layers: 5 conf/models/D.yaml : type : D input_dim : 10 config.yaml defaults: - dataset_reader: A - model: C debug: false Then running the command allennlp compose conf config example -s experiments Produces the file project/experiments/config.json { \"dataset_reader\" :{ \"type\" : \"A\" , \"start_token\" : \"<s>\" , \"end_token\" : \"</s>\" }, \"model\" : { \"type\" : \"C\" , \"layers\" : 5 }, \"debug\" : false } If you want to override the config and use the B dataset reader with the D model, you would modify the previous command: allennlp compose conf config example -s experiments -o model = D dataset_reader = B Produces the file project/experiments/config.json { \"dataset_reader\" :{ \"type\" : \"B\" , \"start_token\" : \"[CLS]\" , \"end_token\" : \"[SEP]\" }, \"model\" : { \"type\" : \"D\" , \"input_dim\" : 10 }, \"debug\" : false } And if you wanted to change input_dim of model D to 25: allennlp compose conf config example -s experiments -o model = D dataset_reader = B model.input_dim = 25 Produces the file project/experiments/config.json { \"dataset_reader\" :{ \"type\" : \"B\" , \"start_token\" : \"[CLS]\" , \"end_token\" : \"[SEP]\" }, \"model\" : { \"type\" : \"D\" , \"input_dim\" : 25 }, \"debug\" : false } ComposeConfig # @Subcommand . register ( \"compose\" ) class ComposeConfig ( Subcommand ) add_subparser # class ComposeConfig ( Subcommand ): | ... | @overrides | def add_subparser ( | self , | parser : argparse . _SubParsersAction | ) -> argparse . ArgumentParser compose_config_from_args # def compose_config_from_args ( args : argparse . Namespace ) -> Dict Wrapper for compose so that it can be called with argparse arguments from the CLI. Parameters \u00b6 args : argparse.Namespace The parsed args from argparse . Returns \u00b6 The composed config. compose_config # def compose_config ( config_path : Union [ str , PathLike ], config_name : str , job_name : str , serialization_dir : Optional [ Union [ str , PathLike ]] = None , config_overrides : List [ str ] = None , fill_defaults : bool = False ) -> Dict Create an AllenNLP config by composing a set of yaml files with Hydra's Compose API . Overriding using Hydra's Override Grammar is also supported. Parameters \u00b6 config_path : Union[str, PathLike] Path to the root config directory. config_name : str The name of the root config file. job_name : str The job name. This is passed to Hydra and is not used here. serialization_dir : Optional[Union[str, PathLike]] , optional (default = None ) If this is passed, it is the directory where the new AllenNLP config will be saved to. The name used for saving will be the config_name and it will be a .json file. config_overrides : List[str] , optional (default = [] ) List of overrides using Hydra's override grammar for the config. fill_defaults : bool , optional (default = False ) Add arguments and their default values to the config if they are not specified. Returns \u00b6 Dict The dictionary config generated by Hydra.","title":"compose_config"},{"location":"hydra/commands/compose_config/#composeconfig","text":"@Subcommand . register ( \"compose\" ) class ComposeConfig ( Subcommand )","title":"ComposeConfig"},{"location":"hydra/commands/compose_config/#add_subparser","text":"class ComposeConfig ( Subcommand ): | ... | @overrides | def add_subparser ( | self , | parser : argparse . _SubParsersAction | ) -> argparse . ArgumentParser","title":"add_subparser"},{"location":"hydra/commands/compose_config/#compose_config_from_args","text":"def compose_config_from_args ( args : argparse . Namespace ) -> Dict Wrapper for compose so that it can be called with argparse arguments from the CLI.","title":"compose_config_from_args"},{"location":"hydra/commands/compose_config/#compose_config","text":"def compose_config ( config_path : Union [ str , PathLike ], config_name : str , job_name : str , serialization_dir : Optional [ Union [ str , PathLike ]] = None , config_overrides : List [ str ] = None , fill_defaults : bool = False ) -> Dict Create an AllenNLP config by composing a set of yaml files with Hydra's Compose API . Overriding using Hydra's Override Grammar is also supported.","title":"compose_config"},{"location":"hydra/commands/hydra_train/","text":"allennlp_hydra .commands .hydra_train [SOURCE] The hydra-train creates an AllenNLP config by composing a set of yaml files with Hydra's Compose API then passing it to AllenNLP's train method. Overriding using Hydra's Override Grammar is also supported. The hydra-train command uses the underlying functionality of the compose command. So the use that documentation for understanding the composition of .yaml files. Parameters \u00b6 config_path : Union[str, PathLike] Path to the root config directory. config_name : str The name of the root config file. Do NOT include the .yaml . job_name : str The job name. This is passed to Hydra and is not used here. -s/--serialization-dir : Union[str, PathLike] The directory where everything is saved. -r/--recover : bool , optional (default = False ) Flag. Recover training from the state in serialization_dir -f/--force : bool , optional (default = False ) Flag. Overwrite the output directory if it exists. --node-rank : int , optional (default = 0 ) The rank of this node in the distributed setup --dry-run : bool , optional (default = False ) Flag. Do not train the model, but create a vocabulary, show dataset statistics and other training information --file-friendly-logging : bool , optional (default = False ) Flag. Outputs tqdm status on separate lines and slows tqdm refresh rate -o/--overrides : List[str] , optional (default = [] ) Keyword arguments passed will be used as a list of overrides using Hydra's override grammar for the config. Example usage: --overrides A = B C = \"D\" Will be interpreted as overrides ['A=B', 'C=\"D\"'] HydraTrain # @Subcommand . register ( \"hydra-train\" ) class HydraTrain ( Subcommand ) add_subparser # class HydraTrain ( Subcommand ): | ... | @overrides | def add_subparser ( | self , | parser : argparse . _SubParsersAction | ) -> argparse . ArgumentParser hydra_train_model_from_args # def hydra_train_model_from_args ( args : argparse . Namespace ) Just converts from an argparse.Namespace object to string paths.","title":"hydra_train"},{"location":"hydra/commands/hydra_train/#hydratrain","text":"@Subcommand . register ( \"hydra-train\" ) class HydraTrain ( Subcommand )","title":"HydraTrain"},{"location":"hydra/commands/hydra_train/#add_subparser","text":"class HydraTrain ( Subcommand ): | ... | @overrides | def add_subparser ( | self , | parser : argparse . _SubParsersAction | ) -> argparse . ArgumentParser","title":"add_subparser"},{"location":"hydra/commands/hydra_train/#hydra_train_model_from_args","text":"def hydra_train_model_from_args ( args : argparse . Namespace ) Just converts from an argparse.Namespace object to string paths.","title":"hydra_train_model_from_args"},{"location":"hydra/config/fill_defaults/","text":"allennlp_hydra .config .fill_defaults [SOURCE] Module for adding arguments and their default values to a config. fill_config_with_default_values # def fill_config_with_default_values ( base_class : Union [ FromParams , Registrable ], config : Dict ) -> Dict Fill a config with the arguments and their default values from a base_class . When it encounters nested objects (i.e. non-builtin classes, for now limited to AllenNLP FromParams and Registrable ) it will recurse and create the dictionary with defaults. This does NOT change the mutable config nor does it override keys if they exist in the config. NOTE: When AllenNLP expands upon their to_params api, this will rely on that, but for the time being it relies on the inspect module. Parameters \u00b6 base_class : Union[FromParams, Registrable] The base class that you want to use to fill the config with the arguments and their default values. These arguments are for the base_class.__init__ function. config : Dict The configuration dict to fill with the defaults. It does NOT make any changes to the mutable data but instead uses deepcopy to copy it to a new object. Existing keys will not be overwritten. Returns \u00b6 cfg_with_defaults : Dict The filled config with defaults. get_default_value_for_parameter # def get_default_value_for_parameter ( parameter : inspect . Parameter ) -> Any Get the default value for a parameter. If there is a type annotation, check if it is a subclass of Registrable. If that is the case, check if the default value is an instance of that class. If it is, then recurse. Otherwise continue. Handles the case where the default value is an initialized registrable. We also find what name the class was registered as to add that as the type value. Parameters \u00b6 parameter: `inspect.Parameter` The parameter to get the default value of. Returns \u00b6 Any The default value of the parameter. get_annotation_class # def get_annotation_class ( parameter : inspect . Parameter ) -> Union [ type , None ] Get the class of the annotation. Parameters \u00b6 parameter: `inspect.Parameter` The parameter to get the class of. Returns \u00b6 Union[type, None] The type or None. get_positional_arguments # def get_positional_arguments ( cls_type : FromParams ) -> Iterable [ str ] Get the init parameters from the underlying class of initialized_class","title":"fill_defaults"},{"location":"hydra/config/fill_defaults/#fill_config_with_default_values","text":"def fill_config_with_default_values ( base_class : Union [ FromParams , Registrable ], config : Dict ) -> Dict Fill a config with the arguments and their default values from a base_class . When it encounters nested objects (i.e. non-builtin classes, for now limited to AllenNLP FromParams and Registrable ) it will recurse and create the dictionary with defaults. This does NOT change the mutable config nor does it override keys if they exist in the config. NOTE: When AllenNLP expands upon their to_params api, this will rely on that, but for the time being it relies on the inspect module.","title":"fill_config_with_default_values"},{"location":"hydra/config/fill_defaults/#get_default_value_for_parameter","text":"def get_default_value_for_parameter ( parameter : inspect . Parameter ) -> Any Get the default value for a parameter. If there is a type annotation, check if it is a subclass of Registrable. If that is the case, check if the default value is an instance of that class. If it is, then recurse. Otherwise continue. Handles the case where the default value is an initialized registrable. We also find what name the class was registered as to add that as the type value.","title":"get_default_value_for_parameter"},{"location":"hydra/config/fill_defaults/#get_annotation_class","text":"def get_annotation_class ( parameter : inspect . Parameter ) -> Union [ type , None ] Get the class of the annotation.","title":"get_annotation_class"},{"location":"hydra/config/fill_defaults/#get_positional_arguments","text":"def get_positional_arguments ( cls_type : FromParams ) -> Iterable [ str ] Get the init parameters from the underlying class of initialized_class","title":"get_positional_arguments"},{"location":"hydra/utils/testing/test_case/","text":"allennlp_hydra .utils .testing .test_case [SOURCE] PROJECT_ROOT # PROJECT_ROOT = pathlib . Path ( __file__ ) . parents [ 3 ] . resolve () TEST_ROOT # TEST_ROOT = PROJECT_ROOT . joinpath ( \"tests\" ) FIXTURES_ROOT # FIXTURES_ROOT = PROJECT_ROOT . joinpath ( \"test_fixtures\" ) BaseTestCase # class BaseTestCase A custom testing class that disables some of the more verbose AllenNLP logging and that creates and destroys a temp directory as a test fixture. PROJECT_ROOT # class BaseTestCase : | ... | PROJECT_ROOT = PROJECT_ROOT MODULE_ROOT # class BaseTestCase : | ... | MODULE_ROOT = PROJECT_ROOT / \"src\" TESTS_ROOT # class BaseTestCase : | ... | TESTS_ROOT = TEST_ROOT FIXTURES_ROOT # class BaseTestCase : | ... | FIXTURES_ROOT = FIXTURES_ROOT FIXTURES_DATA_PATH # class BaseTestCase : | ... | FIXTURES_DATA_PATH = FIXTURES_ROOT / \"data\" test_dir # class BaseTestCase : | ... | @pytest . fixture ( autouse = True ) | def test_dir ( self , tmpdir ) setup_method # class BaseTestCase : | ... | def setup_method ( self )","title":"test_case"},{"location":"hydra/utils/testing/test_case/#project_root","text":"PROJECT_ROOT = pathlib . Path ( __file__ ) . parents [ 3 ] . resolve ()","title":"PROJECT_ROOT"},{"location":"hydra/utils/testing/test_case/#test_root","text":"TEST_ROOT = PROJECT_ROOT . joinpath ( \"tests\" )","title":"TEST_ROOT"},{"location":"hydra/utils/testing/test_case/#fixtures_root","text":"FIXTURES_ROOT = PROJECT_ROOT . joinpath ( \"test_fixtures\" )","title":"FIXTURES_ROOT"},{"location":"hydra/utils/testing/test_case/#basetestcase","text":"class BaseTestCase A custom testing class that disables some of the more verbose AllenNLP logging and that creates and destroys a temp directory as a test fixture.","title":"BaseTestCase"},{"location":"hydra/utils/testing/test_case/#project_root_1","text":"class BaseTestCase : | ... | PROJECT_ROOT = PROJECT_ROOT","title":"PROJECT_ROOT"},{"location":"hydra/utils/testing/test_case/#module_root","text":"class BaseTestCase : | ... | MODULE_ROOT = PROJECT_ROOT / \"src\"","title":"MODULE_ROOT"},{"location":"hydra/utils/testing/test_case/#tests_root","text":"class BaseTestCase : | ... | TESTS_ROOT = TEST_ROOT","title":"TESTS_ROOT"},{"location":"hydra/utils/testing/test_case/#fixtures_root_1","text":"class BaseTestCase : | ... | FIXTURES_ROOT = FIXTURES_ROOT","title":"FIXTURES_ROOT"},{"location":"hydra/utils/testing/test_case/#fixtures_data_path","text":"class BaseTestCase : | ... | FIXTURES_DATA_PATH = FIXTURES_ROOT / \"data\"","title":"FIXTURES_DATA_PATH"},{"location":"hydra/utils/testing/test_case/#test_dir","text":"class BaseTestCase : | ... | @pytest . fixture ( autouse = True ) | def test_dir ( self , tmpdir )","title":"test_dir"},{"location":"hydra/utils/testing/test_case/#setup_method","text":"class BaseTestCase : | ... | def setup_method ( self )","title":"setup_method"},{"location":"hydra/utils/testing/utils/","text":"allennlp_hydra .utils .testing .utils [SOURCE] assert_models_weights_equal # def assert_models_weights_equal ( model_1 , model_2 )","title":"utils"},{"location":"hydra/utils/testing/utils/#assert_models_weights_equal","text":"def assert_models_weights_equal ( model_1 , model_2 )","title":"assert_models_weights_equal"}]}